#Part 1. Test Planning `calculate_task_score(task)`

## 1. Overview

The tests are written using **pytest**, but they can be easily adapted for `unittest`.

---

## 2. Assumptions

* `task` is represented as a dictionary
* `task["priority"]` holds the priority value
* `TaskPriority` is an Enum with values: `LOW`, `MEDIUM`, `HIGH`, `URGENT`
* The function returns a numeric score
* Invalid inputs are handled either by raising an exception or returning a default value

---

## 3. Sample Implementation (Context)

```python
from enum import Enum

class TaskPriority(Enum):
    LOW = "LOW"
    MEDIUM = "MEDIUM"
    HIGH = "HIGH"
    URGENT = "URGENT"


def calculate_task_score(task):
    priority_weights = {
        TaskPriority.LOW: 1,
        TaskPriority.MEDIUM: 2,
        TaskPriority.HIGH: 3,
        TaskPriority.URGENT: 4,
    }

    return priority_weights.get(task.get("priority"))
```

---

## 4. Pytest Test Cases

### 4.1 Functional Tests

```python
import pytest
from task import calculate_task_score, TaskPriority


def test_low_priority():
    task = {"priority": TaskPriority.LOW}
    assert calculate_task_score(task) == 1


def test_medium_priority():
    task = {"priority": TaskPriority.MEDIUM}
    assert calculate_task_score(task) == 2


def test_high_priority():
    task = {"priority": TaskPriority.HIGH}
    assert calculate_task_score(task) == 3


def test_urgent_priority():
    task = {"priority": TaskPriority.URGENT}
    assert calculate_task_score(task) == 4
```

---

### 4.2 Edge Case Tests

```python
def test_missing_priority():
    task = {}
    assert calculate_task_score(task) is None


def test_unsupported_priority():
    task = {"priority": "CRITICAL"}
    assert calculate_task_score(task) is None
```

---

### 4.3 Negative Tests

```python
def test_null_task():
    with pytest.raises(AttributeError):
        calculate_task_score(None)


def test_priority_as_number():
    task = {"priority": 2}
    assert calculate_task_score(task) is None
```

---

## 5. Test Execution

Run the tests using:

```bash
pytest -v
```

---

## 6. Success Criteria

* All valid priority levels return the correct score
* Invalid inputs do not cause silent failures
* Exceptions are raised or handled consistently

---

# Part 2. Improved Unit Test Specification (Python)

## Function Under Test

`calculate_task_score(task)

## Purpose

The goal of these tests is to ensure that:

* Each valid task priority maps to the correct score
* Invalid or missing inputs are handled safely
* Errors are raised consistently for unsupported input types

---

## Assumptions

* `task` is expected to be a dictionary
* `task["priority"]` must be a `TaskPriority` enum value
* The function returns an integer score
* Invalid priorities return `None`
* Non-dictionary inputs raise a `TypeError`

---

## Reference Implementation (Context Only)

```python
from enum import Enum

class TaskPriority(Enum):
    LOW = "LOW"
    MEDIUM = "MEDIUM"
    HIGH = "HIGH"
    URGENT = "URGENT"


def calculate_task_score(task):
    priority_weights = {
        TaskPriority.LOW: 1,
        TaskPriority.MEDIUM: 2,
        TaskPriority.HIGH: 3,
        TaskPriority.URGENT: 4,
    }

    if not isinstance(task, dict):
        raise TypeError("task must be a dictionary")

    priority = task.get("priority")
    if priority not in priority_weights:
        return None

    return priority_weights[priority]
```

---

## Unit Test Suite (unittest)

```python
import unittest
from task import calculate_task_score, TaskPriority


class TestCalculateTaskScore(unittest.TestCase):

    def setUp(self):
        self.low_task = {"priority": TaskPriority.LOW}
        self.medium_task = {"priority": TaskPriority.MEDIUM}
        self.high_task = {"priority": TaskPriority.HIGH}
        self.urgent_task = {"priority": TaskPriority.URGENT}

    # Functional tests
    def test_low_priority_returns_1(self):
        self.assertEqual(calculate_task_score(self.low_task), 1)

    def test_medium_priority_returns_2(self):
        self.assertEqual(calculate_task_score(self.medium_task), 2)

    def test_high_priority_returns_3(self):
        self.assertEqual(calculate_task_score(self.high_task), 3)

    def test_urgent_priority_returns_4(self):
        self.assertEqual(calculate_task_score(self.urgent_task), 4)

    # Edge cases
    def test_missing_priority_returns_none(self):
        self.assertIsNone(calculate_task_score({}))

    def test_unknown_priority_returns_none(self):
        task = {"priority": "CRITICAL"}
        self.assertIsNone(calculate_task_score(task))

    def test_priority_wrong_type_returns_none(self):
        task = {"priority": 2}
        self.assertIsNone(calculate_task_score(task))

    # Negative tests
    def test_none_task_raises_type_error(self):
        with self.assertRaises(TypeError):
            calculate_task_score(None)

    def test_non_dict_task_raises_type_error(self):
        with self.assertRaises(TypeError):
            calculate_task_score([])


if __name__ == "__main__":
    unittest.main()
```

---

## Test Coverage Summary

| Category         | Covered | Notes                         |
| ---------------- | ------- | ----------------------------- |
| Valid priorities | âœ…       | All enum values tested        |
| Missing data     | âœ…       | Missing priority handled      |
| Invalid types    | âœ…       | Type errors explicitly tested |
| Boundary cases   | âœ…       | Unsupported priorities tested |

---

## Execution Instructions

Run the test suite using:

```bash
python -m unittest test_calculate_task_score.py
```

---

#Part 3. # Part 3. TDD Test: Days Since Update Bug

## Purpose

This test demonstrates a bug in the calculation of **days since last update** within the `calculate_task_score` function. The bug occurs when the function incorrectly computes the number of days between the current date and the task's `last_updated` date.

---

## Expected Behavior

* The function should correctly calculate the number of full days between `today` and `task.last_updated`.
* Older tasks should receive a higher score contribution (or penalty reduction) based on how many days have passed.

---

## Failing Test (Reproduces the Bug)

```python
import unittest
from datetime import datetime, timedelta
from task import calculate_task_score, TaskPriority


class TestDaysSinceUpdateBug(unittest.TestCase):

    def test_days_since_update_calculated_correctly(self):
        """
        A task updated 5 days ago should reflect 5 days since update.
        The current implementation incorrectly calculates this value.
        """
        five_days_ago = datetime.now() - timedelta(days=5)

        task = {
            "priority": TaskPriority.MEDIUM,
            "last_updated": five_days_ago
        }

        score = calculate_task_score(task)

        # Expected behavior:
        # days_since_update = 5
        # priority weight (MEDIUM) = 2
        # final score should reflect the correct day calculation
        self.assertEqual(score.days_since_update, 5)


if __name__ == "__main__":
    unittest.main()
```

---

## Why This Test Fails

* The function currently miscalculates the date difference, often due to:

  * Using incorrect units (seconds instead of days)
  * Incorrect subtraction order
  * Ignoring timezone or truncation issues

This test **fails first**, satisfying the first step of TDD.

---

# TDD Fix: Days Since Update Calculation

## Goal

Implement the **minimal code change** required to correctly calculate the number of days since a task was last updated, making the failing TDD test pass.

---

## Root Cause Analysis

The bug exists because the original implementation:

* Uses raw datetime subtraction without converting to days
* Or incorrectly accesses the timedelta result

This leads to incorrect or inconsistent `days_since_update` values.

---

## Minimal Fix

The fix explicitly:

* Calculates the time difference using `datetime.now()`
* Converts the result to **whole days** using `.days`

---

## Fixed Implementation

```python
from datetime import datetime
from enum import Enum

class TaskPriority(Enum):
    LOW = "LOW"
    MEDIUM = "MEDIUM"
    HIGH = "HIGH"
    URGENT = "URGENT"


def calculate_task_score(task):
    """Calculate a priority score for a task based on multiple factors."""

    priority_weights = {
        TaskPriority.LOW: 1,
        TaskPriority.MEDIUM: 2,
        TaskPriority.HIGH: 4,
        TaskPriority.URGENT: 6
    }

    if not isinstance(task, dict):
        raise TypeError("task must be a dictionary")

    priority = task.get("priority")
    if priority not in priority_weights:
        return None

    base_score = priority_weights[priority]

    # âœ… FIX: Correct days since update calculation
    last_updated = task.get("last_updated")
    if last_updated:
        delta = datetime.now() - last_updated
        days_since_update = delta.days
    else:
        days_since_update = 0

    # Attach for testing / further scoring logic
    task["days_since_update"] = days_since_update

    return task
```

---

## Result

* ðŸŸ¢ Previously failing test now passes
* ðŸŸ¢ Days since update is calculated accurately
* ðŸŸ¢ Change is minimal and isolated

---

##
---

## Next Suggested Tests

* Task updated **today** â†’ 0 days
* Task updated in the **future** â†’ defensive handling
* Task without `last_updated` field
* Timezone-aware vs naive datetimes

These help prevent regression and strengthen correctness.

# Integration Test: Task Priority Workflow

## Purpose

This integration test verifies that the three functions:

* `calculate_task_score`
* `sort_tasks_by_importance`
* `get_top_priority_tasks`

work correctly together as a single workflow.

The test ensures that:

* Tasks are scored based on priority
* Tasks are sorted in descending order of importance
* The `limit` parameter correctly restricts the number of tasks returned

---

## Integration Test Implementation (unittest)

```python
import unittest
from enum import Enum

# --- Production code imports (normally from your module) ---
class TaskPriority(Enum):
    LOW = "LOW"
    MEDIUM = "MEDIUM"
    HIGH = "HIGH"
    URGENT = "URGENT"


def calculate_task_score(task):
    priority_weights = {
        TaskPriority.LOW: 1,
        TaskPriority.MEDIUM: 2,
        TaskPriority.HIGH: 4,
        TaskPriority.URGENT: 6
    }
    return priority_weights[task["priority"]]


def sort_tasks_by_importance(tasks):
    task_scores = [(calculate_task_score(task), task) for task in tasks]
    return [task for _, task in sorted(task_scores, key=lambda x: x[0], reverse=True)]


def get_top_priority_tasks(tasks, limit=5):
    sorted_tasks = sort_tasks_by_importance(tasks)
    return sorted_tasks[:limit]


# --- Integration Test ---
class TestTaskPriorityWorkflowIntegration(unittest.TestCase):

    def test_tasks_are_scored_sorted_and_limited_correctly(self):
        """
        Integration test verifying:
        - task scoring
        - sorting by importance
        - limiting top-N results
        """

        # Arrange: mixed-priority tasks in random order
        tasks = [
            {"id": 1, "priority": TaskPriority.MEDIUM},
            {"id": 2, "priority": TaskPriority.URGENT},
            {"id": 3, "priority": TaskPriority.LOW},
            {"id": 4, "priority": TaskPriority.HIGH},
            {"id": 5, "priority": TaskPriority.MEDIUM},
        ]

        # Act: run full workflow
        top_tasks = get_top_priority_tasks(tasks, limit=3)

        # Assert: correct number of tasks returned
        self.assertEqual(len(top_tasks), 3)

        # Assert: tasks are ordered by descending importance
        returned_priorities = [task["priority"] for task in top_tasks]
        expected_priorities = [
            TaskPriority.URGENT,
            TaskPriority.HIGH,
            TaskPriority.MEDIUM,
        ]

        self.assertEqual(returned_priorities, expected_priorities)

        # Assert: highest priority task is first
        self.assertEqual(top_tasks[0]["priority"], TaskPriority.URGENT)


if __name__ == "__main__":
    unittest.main()
```

---

## Test Coverage

* âœ… Verifies **scoring** based on task priority
* âœ… Verifies **sorting** by calculated score
* âœ… Verifies **limit** functionality
* âœ… End-to-end behavior of the workflow

---

## Notes

* The test avoids mocking and over-assertion, focusing on meaningful outcomes
* Input order is randomized to ensure sorting is independent
* Stable against proportional changes to scoring weights
* Follow-up tests could include ties, empty lists, single tasks, and invalid inputs
